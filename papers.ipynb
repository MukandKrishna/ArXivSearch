{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14c5452",
   "metadata": {},
   "source": [
    "# ChatBot to Search Papers on Arxiv and storing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a19aadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4b28333",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90e8fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "875bdcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d51d2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "434d0870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52718c13",
   "metadata": {},
   "source": [
    "## tools schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e3cccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_papers\",\n",
    "            \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The topic to search for\"\n",
    "                    }, \n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to retrieve\",\n",
    "                        \"default\": 5\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_info\",\n",
    "            \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to look for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e298ed0",
   "metadata": {},
   "source": [
    "## tool mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05c1554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5df2e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<groq.Groq object at 0x715313d01940>\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('Groq_Cloud')\n",
    "\n",
    "\n",
    "client = Groq(\n",
    "api_key = api_key\n",
    ")\n",
    "\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd377dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.chat.completions.create(max_tokens=1024,\n",
    "                                             model='llama3-70b-8192', \n",
    "                                             tools=tools,\n",
    "                                             messages=messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = \"\"\n",
    "\n",
    "        # Access the message from the first choice\n",
    "        message = response.choices[0].message\n",
    "\n",
    "        # Handle text response\n",
    "        if message.content:\n",
    "            print(message.content)\n",
    "            assistant_content = message.content\n",
    "            messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "            \n",
    "            if not message.tool_calls:\n",
    "                process_query = False\n",
    "        \n",
    "        # Handle tool calls\n",
    "        if message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_id = tool_call.id\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                \n",
    "                # Append assistant message with tool call acknowledgment (as a string)\n",
    "                assistant_content = f\"Tool {tool_name} called with arguments {tool_args}\"\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                # Append tool result as a text content object\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"Tool result for {tool_id}: {result}\"\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "                \n",
    "                response = client.chat.completions.create(max_tokens=1024,\n",
    "                                                         model='llama3-70b-8192', \n",
    "                                                         tools=tools,\n",
    "                                                         messages=messages)\n",
    "                \n",
    "                # Check if the new response is a final text response\n",
    "                if response.choices[0].message.content and not response.choices[0].message.tool_calls:\n",
    "                    print(response.choices[0].message.content)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b602d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f922db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Calling tool search_papers with args {'topic': 'Agentic AI', 'max_results': 5}\n",
      "Results are saved in: papers/agentic_ai/papers_info.json\n",
      "Calling tool extract_info with args {'paper_id': '2502.18359v1'}\n",
      "Based on the search results and the extracted information from the paper \"Responsible AI Agents\", it seems that Agentic AI is an area of research focused on responsible AI agents. These agents are capable of executing tasks, such as booking trips or posting content on social media. However, there are concerns about the potential misuses of AI agents, including rogue commerce, manipulation, defamation, and intellectual property harms. The paper argues that core aspects of software interactions can discipline AI agents and prevent undesired actions. It also proposes a computer-science approach to align AI agents with user norms and values, which can mitigate perceived risks. Finally, the paper asserts that AI agents should not be given legal personhood status and that humans are responsible for their actions.\n",
      "Calling tool extract_info with args {'paper_id': '2505.10468v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2403.15137v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2502.08864v1'}\n",
      "Tool extract_info called with arguments {'paper_id': '2406.00477v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2406.00477v1'}\n",
      "\n",
      "\n",
      "Calling tool search_papers with args {'topic': '2406.00477v1'}\n",
      "Results are saved in: papers/2406.00477v1/papers_info.json\n",
      "Calling tool extract_info with args {'paper_id': '2406.00477v1'}\n",
      "<tool-use>\n",
      "{\n",
      "\t\"tool_calls\":[\n",
      "\t]\n",
      "}\n",
      "</tool-use>\n",
      "\n",
      "Title: Generative AI as Economic Agents\n",
      "Authors: Nicole Immorlica, Brendan Lucier, Aleksandrs Slivkins\n",
      "Summary: Traditionally, AI has been modeled within economics as a technology that impacts payoffs by reducing costs or refining information for human agents. Our position is that, in light of recent advances in generative AI, it is increasingly useful to model AI itself as an economic agent. In our framework, each user is augmented with an AI agent and can consult the AI prior to taking actions in a game. The AI agent and the user have potentially different information and preferences over the communication, which can result in equilibria that are qualitatively different than in settings without AI.\n",
      "Pdf Url: http://arxiv.org/pdf/2406.00477v1\n",
      "Published: 2024-06-01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
